# src/agents/doc_agent.py
from loguru import logger
from llama_index.core.agent import AgentRunner, ReActAgentWorker
# from llama_index.core.agent.workflow import FunctionAgent

from src.core.llm import get_llm
from src.core.schemas import OutputSchema # CodeInputSchema no longer direct input
from src.core.utils import parse_thinking_outputs
from src.core.mcp_tools import (
    adapted_pydocstyle_mcp_tool, # The LlamaIndex tool
    get_all_tool_outputs,
    clear_tool_outputs,
    # mcp_tool_wrapper is not directly called by DocAgent's main logic anymore,
    # but by the adapted_pydocstyle_mcp_tool.
)

class DocAgent:
    def __init__(self):
        self.llm = get_llm()
        # Tools specific to this agent
        self.tools = [adapted_pydocstyle_mcp_tool]

        self.agent_worker = ReActAgentWorker.from_tools(
            tools=self.tools,
            llm=self.llm,
            verbose=True  # Enable verbose logging for the agent's thoughts
        )
        self.agent = AgentRunner(self.agent_worker, llm=self.llm, verbose=True)
        logger.info(f"DocAgent initialized with LLM: {self.llm.model if hasattr(self.llm, 'model') else type(self.llm).__name__} and Agent: {type(self.agent).__name__}")
        logger.info(f"DocAgent tools: {[tool.metadata.name for tool in self.tools]}")


    def analyze_documentation(self, query: str) -> OutputSchema:
        prompt = f"""
        Analyzes the documentation of the provided code snippet using its LLM agent.
        Analyze the documentation of the following Python code. 
        Focus on PEP 257 compliance and general docstring quality. 
        Provide a summary of findings and detailed issues if any.
        The output must only be in the following JSON format. Do not output anything other than this JSON object:
        {{
            "issue": "Issues found in the code",
            "reason": "Reason for the issue and reasons for tagging them as issues",
            "fixed_code": "Fixed code",
            "feedback": "Feedback for the code"
        }}

        --- CODE START ---
        {query}
        --- CODE END ---
        """
        logger.info(f"DocAgent: Received query for documentation analysis:\n{query}")
        
        # Clear any previous global tool outputs before this agent runs its tools
        # This is important if multiple agents use the same global list.
        clear_tool_outputs() 

        try:
            # The DocAgent's LLM will process the query and decide to use pydocstyle_mcp_tool
            agent_response = self.agent.query(prompt).response
            
            llm_json_response = parse_thinking_outputs(agent_response)
            logger.info(f"DocAgent: LLM JSON response: {llm_json_response}")

            # Retrieve outputs from tools called by *this* agent during *this* query
            tool_outputs_data = get_all_tool_outputs() 
            
            # We need to transform these raw tool outputs into OutputCodeLine if needed,
            # or decide if the llm_text_response is sufficient.
            # For now, let's assume the orchestrator will primarily look at DocAgent's LLM response
            # and the structured tool_outputs_data.
            # The OutputSchema for DocAgent might be simpler, focusing on its findings.

            # Let's create a generic OutputCodeLine for the agent's summary
            # and then add detailed findings from tools if available.
            
            final_output_schema: Optional[OutputSchema] = None

            if llm_json_response:
                final_output_schema = OutputSchema(
                    code=query, # Or relevant snippet if identifiable
                    issue=llm_json_response.get("issue", "Unknown Issue"),
                    feedback=llm_json_response.get("feedback", "No feedback provided"),
                    fixed_code=llm_json_response.get("fixed_code", query),
                    reason=llm_json_response.get("reason", "Summary from Documentation Analysis Agent LLM.")
                )

            # Process tool outputs if any were generated by this agent's run
            for tool_call_data in tool_outputs_data:
                # Example: tool_call_data = {'tool_name': 'pydocstyle_mcp_tool', 'output': {...}, 'raw_input':{...}}
                if tool_call_data.get("tool_name") == "pydocstyle_mcp_tool":
                    pydocstyle_output = tool_call_data.get("output", {})
                    pydocstyle_errors = pydocstyle_output.get("errors", [])
                    for error in pydocstyle_errors:
                        final_output_schema = OutputSchema(
                            code=query, # Could try to get from raw_input if complex
                            line_number=error.get("line", 0),
                            issue=f"Pydocstyle-{error.get('code')}",
                            feedback=error.get('message'),
                            fixed_code=query,
                            reason=f"Docstring convention violation ({error.get('code')})."
                        )
            
            if not tool_outputs_data:
                logger.info("DocAgent: No specific tool outputs captured by this agent's run.")

        except Exception as e:
            logger.exception("DocAgent: Error during documentation analysis agent execution:")
            final_output_schema = OutputSchema(
                    code="", 
                    issue="DocAgent Execution Error", 
                    feedback=f"Error in DocAgent: {str(e)}",
                    fixed_code="", 
                    reason="Exception during agent processing."
                )
        
        # Clear outputs again to ensure they don't leak to the next agent/orchestrator phase
        # if the orchestrator isn't managing this strictly.
        # clear_tool_outputs() # Or the orchestrator handles this after collecting agent's response.
        # For now, let DocAgent return its collected outputs. Orchestrator will manage global state.

        logger.info(f"DocAgent: Analysis complete. Returning OutputSchema.")
        return final_output_schema

logger.info("DocAgent (LLM-powered) module loaded.")
